{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Imports ======\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('..')\n",
    "\n",
    "import src.org_net as org_net\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_graphml('../data/orgnetwork.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jackson Paull\\.conda\\envs\\sd\\Lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:53: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\b\\abs_abjetg6_iu\\croot\\pytorch_1686932924616\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  return th.as_tensor(data, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "G_dgl = org_net.clean_graph_pipeline(G) # Create synthetic graph and pass to the clean pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.760510265827179\n",
      "AUC 0.4357368140450407\n",
      "In epoch 5, loss: 0.6849287748336792\n",
      "In epoch 10, loss: 0.6632905006408691\n",
      "In epoch 15, loss: 0.615721583366394\n",
      "In epoch 20, loss: 0.5580089092254639\n",
      "In epoch 25, loss: 0.4992983639240265\n",
      "In epoch 30, loss: 0.4510454833507538\n",
      "In epoch 35, loss: 0.41004976630210876\n",
      "In epoch 40, loss: 0.37609362602233887\n",
      "In epoch 45, loss: 0.3424392640590668\n",
      "In epoch 50, loss: 0.31710854172706604\n",
      "In epoch 55, loss: 0.28962111473083496\n",
      "In epoch 60, loss: 0.2678872048854828\n",
      "In epoch 65, loss: 0.25122788548469543\n",
      "In epoch 70, loss: 0.233723446726799\n",
      "In epoch 75, loss: 0.218282088637352\n",
      "In epoch 80, loss: 0.20549139380455017\n",
      "In epoch 85, loss: 0.1953355073928833\n",
      "In epoch 90, loss: 0.18370361626148224\n",
      "In epoch 95, loss: 0.17885363101959229\n",
      "In epoch 100, loss: 0.16838283836841583\n",
      "AUC 0.9127535642154004\n",
      "In epoch 105, loss: 0.16374389827251434\n",
      "In epoch 110, loss: 0.1536256968975067\n",
      "In epoch 115, loss: 0.14776155352592468\n",
      "In epoch 120, loss: 0.14226789772510529\n",
      "In epoch 125, loss: 0.13658452033996582\n",
      "In epoch 130, loss: 0.13176295161247253\n",
      "In epoch 135, loss: 0.12636922299861908\n",
      "In epoch 140, loss: 0.12801262736320496\n",
      "In epoch 145, loss: 0.1234501525759697\n",
      "In epoch 150, loss: 0.11444471031427383\n",
      "In epoch 155, loss: 0.11425723135471344\n",
      "In epoch 160, loss: 0.11079808324575424\n",
      "In epoch 165, loss: 0.10623838007450104\n",
      "In epoch 170, loss: 0.10280423611402512\n",
      "In epoch 175, loss: 0.09842397272586823\n",
      "In epoch 180, loss: 0.09590310603380203\n",
      "In epoch 185, loss: 0.0934905931353569\n",
      "In epoch 190, loss: 0.0901610404253006\n",
      "In epoch 195, loss: 0.08791937679052353\n",
      "In epoch 200, loss: 0.08514023572206497\n",
      "AUC 0.9382640536613001\n",
      "In epoch 205, loss: 0.08288562297821045\n",
      "In epoch 210, loss: 0.08055916428565979\n",
      "In epoch 215, loss: 0.07832296937704086\n",
      "In epoch 220, loss: 0.07607526332139969\n",
      "In epoch 225, loss: 0.07406528294086456\n",
      "In epoch 230, loss: 0.07199761271476746\n",
      "In epoch 235, loss: 0.07038972526788712\n",
      "In epoch 240, loss: 0.07413995265960693\n",
      "In epoch 245, loss: 0.06775296479463577\n",
      "In epoch 250, loss: 0.06738454103469849\n",
      "In epoch 255, loss: 0.06427579373121262\n",
      "In epoch 260, loss: 0.061780963093042374\n",
      "In epoch 265, loss: 0.060542620718479156\n",
      "In epoch 270, loss: 0.059163469821214676\n",
      "In epoch 275, loss: 0.05764872953295708\n",
      "In epoch 280, loss: 0.05612550675868988\n",
      "In epoch 285, loss: 0.05473099648952484\n",
      "In epoch 290, loss: 0.053598228842020035\n",
      "In epoch 295, loss: 0.052337922155857086\n",
      "In epoch 300, loss: 0.05107814818620682\n",
      "AUC 0.9426448546194202\n",
      "In epoch 305, loss: 0.05083657056093216\n",
      "In epoch 310, loss: 0.07179271429777145\n",
      "In epoch 315, loss: 0.10578746348619461\n",
      "In epoch 320, loss: 0.052778974175453186\n",
      "In epoch 325, loss: 0.05226031318306923\n",
      "In epoch 330, loss: 0.055191729217767715\n",
      "In epoch 335, loss: 0.05447527766227722\n",
      "In epoch 340, loss: 0.04866211488842964\n",
      "In epoch 345, loss: 0.046368349343538284\n",
      "In epoch 350, loss: 0.04601108655333519\n",
      "In epoch 355, loss: 0.04511965811252594\n",
      "In epoch 360, loss: 0.043884120881557465\n",
      "In epoch 365, loss: 0.04288296028971672\n",
      "In epoch 370, loss: 0.042082272469997406\n",
      "In epoch 375, loss: 0.041371237486600876\n",
      "In epoch 380, loss: 0.04076823964715004\n",
      "In epoch 385, loss: 0.04011581093072891\n",
      "In epoch 390, loss: 0.03949321433901787\n",
      "In epoch 395, loss: 0.03890632092952728\n",
      "In epoch 400, loss: 0.03833237290382385\n",
      "AUC 0.9418903580430373\n",
      "In epoch 405, loss: 0.03778287023305893\n",
      "In epoch 410, loss: 0.037249114364385605\n",
      "In epoch 415, loss: 0.036725711077451706\n",
      "In epoch 420, loss: 0.03621950373053551\n",
      "In epoch 425, loss: 0.035725366324186325\n",
      "In epoch 430, loss: 0.03524472191929817\n",
      "In epoch 435, loss: 0.034776926040649414\n",
      "In epoch 440, loss: 0.03432020917534828\n",
      "In epoch 445, loss: 0.03387290984392166\n",
      "In epoch 450, loss: 0.03343285247683525\n",
      "In epoch 455, loss: 0.0329916849732399\n",
      "In epoch 460, loss: 0.03256179764866829\n",
      "In epoch 465, loss: 0.032140884548425674\n",
      "In epoch 470, loss: 0.03172789514064789\n",
      "In epoch 475, loss: 0.03132347762584686\n",
      "In epoch 480, loss: 0.030924085527658463\n",
      "In epoch 485, loss: 0.03053182177245617\n",
      "In epoch 490, loss: 0.030148498713970184\n",
      "In epoch 495, loss: 0.029774105176329613\n",
      "In epoch 500, loss: 0.029408713802695274\n",
      "AUC 0.9409621662588977\n",
      "In epoch 505, loss: 0.029051177203655243\n",
      "In epoch 510, loss: 0.02870151214301586\n",
      "In epoch 515, loss: 0.028359219431877136\n",
      "In epoch 520, loss: 0.028022078797221184\n",
      "In epoch 525, loss: 0.027690397575497627\n",
      "In epoch 530, loss: 0.027363557368516922\n",
      "In epoch 535, loss: 0.02704404667019844\n",
      "In epoch 540, loss: 0.0267325509339571\n",
      "In epoch 545, loss: 0.026424717158079147\n",
      "In epoch 550, loss: 0.02612198144197464\n",
      "In epoch 555, loss: 0.025824230164289474\n",
      "In epoch 560, loss: 0.025532744824886322\n",
      "In epoch 565, loss: 0.025243815034627914\n",
      "In epoch 570, loss: 0.02496039681136608\n",
      "In epoch 575, loss: 0.024682968854904175\n",
      "In epoch 580, loss: 0.024413304403424263\n",
      "In epoch 585, loss: 0.024150419980287552\n",
      "In epoch 590, loss: 0.02389432117342949\n",
      "In epoch 595, loss: 0.02364525943994522\n",
      "In epoch 600, loss: 0.023402245715260506\n",
      "AUC 0.9398436666160376\n",
      "In epoch 605, loss: 0.02316565439105034\n",
      "In epoch 610, loss: 0.02293521724641323\n",
      "In epoch 615, loss: 0.022710023447871208\n",
      "In epoch 620, loss: 0.022490864619612694\n",
      "In epoch 625, loss: 0.022276828065514565\n",
      "In epoch 630, loss: 0.022068461403250694\n",
      "In epoch 635, loss: 0.021860670298337936\n",
      "In epoch 640, loss: 0.021663103252649307\n",
      "In epoch 645, loss: 0.021465864032506943\n",
      "In epoch 650, loss: 0.021275769919157028\n",
      "In epoch 655, loss: 0.021091774106025696\n",
      "In epoch 660, loss: 0.020910706371068954\n",
      "In epoch 665, loss: 0.02074306644499302\n",
      "In epoch 670, loss: 0.020568950101733208\n",
      "In epoch 675, loss: 0.02040056698024273\n",
      "In epoch 680, loss: 0.020231515169143677\n",
      "In epoch 685, loss: 0.02007061429321766\n",
      "In epoch 690, loss: 0.019912905991077423\n",
      "In epoch 695, loss: 0.019758092239499092\n",
      "In epoch 700, loss: 0.019607368856668472\n",
      "AUC 0.9400578351162963\n",
      "In epoch 705, loss: 0.01946023851633072\n",
      "In epoch 710, loss: 0.01931489259004593\n",
      "In epoch 715, loss: 0.019172828644514084\n",
      "In epoch 720, loss: 0.01903388649225235\n",
      "In epoch 725, loss: 0.018898960202932358\n",
      "In epoch 730, loss: 0.018773073330521584\n",
      "In epoch 735, loss: 0.01869037374854088\n",
      "In epoch 740, loss: 0.018560392782092094\n",
      "In epoch 745, loss: 0.018486537039279938\n",
      "In epoch 750, loss: 0.018390405923128128\n",
      "In epoch 755, loss: 0.018181277438998222\n",
      "In epoch 760, loss: 0.018141405656933784\n",
      "In epoch 765, loss: 0.017951229587197304\n",
      "In epoch 770, loss: 0.01785968616604805\n",
      "In epoch 775, loss: 0.017726248130202293\n",
      "In epoch 780, loss: 0.017619334161281586\n",
      "In epoch 785, loss: 0.017519503831863403\n",
      "In epoch 790, loss: 0.01741362363100052\n",
      "In epoch 795, loss: 0.01731560006737709\n",
      "In epoch 800, loss: 0.017221719026565552\n",
      "AUC 0.9395690126723097\n",
      "In epoch 805, loss: 0.01712852343916893\n",
      "In epoch 810, loss: 0.017037589102983475\n",
      "In epoch 815, loss: 0.01694866083562374\n",
      "In epoch 820, loss: 0.016861720010638237\n",
      "In epoch 825, loss: 0.01677670143544674\n",
      "In epoch 830, loss: 0.01669376716017723\n",
      "In epoch 835, loss: 0.016612235456705093\n",
      "In epoch 840, loss: 0.016532232984900475\n",
      "In epoch 845, loss: 0.01645432971417904\n",
      "In epoch 850, loss: 0.01637723669409752\n",
      "In epoch 855, loss: 0.01630197837948799\n",
      "In epoch 860, loss: 0.016228921711444855\n",
      "In epoch 865, loss: 0.01615603268146515\n",
      "In epoch 870, loss: 0.016086220741271973\n",
      "In epoch 875, loss: 0.016016706824302673\n",
      "In epoch 880, loss: 0.01595195196568966\n",
      "In epoch 885, loss: 0.015892120078206062\n",
      "In epoch 890, loss: 0.015818234533071518\n",
      "In epoch 895, loss: 0.015780016779899597\n",
      "In epoch 900, loss: 0.015759894624352455\n",
      "AUC 0.9385481364069261\n",
      "In epoch 905, loss: 0.015633555129170418\n",
      "In epoch 910, loss: 0.015625430271029472\n",
      "In epoch 915, loss: 0.015512453392148018\n",
      "In epoch 920, loss: 0.015473220497369766\n",
      "In epoch 925, loss: 0.01545408833771944\n",
      "In epoch 930, loss: 0.015350217930972576\n",
      "In epoch 935, loss: 0.01527535542845726\n",
      "In epoch 940, loss: 0.015230044722557068\n",
      "In epoch 945, loss: 0.015269724652171135\n",
      "In epoch 950, loss: 0.015507686883211136\n",
      "In epoch 955, loss: 0.015105956234037876\n",
      "In epoch 960, loss: 0.015115227550268173\n",
      "In epoch 965, loss: 0.015013225376605988\n",
      "In epoch 970, loss: 0.014959190972149372\n",
      "In epoch 975, loss: 0.014924220740795135\n",
      "In epoch 980, loss: 0.014859618619084358\n",
      "In epoch 985, loss: 0.014782419428229332\n",
      "In epoch 990, loss: 0.014781516045331955\n",
      "In epoch 995, loss: 0.014738637022674084\n",
      "In epoch 1000, loss: 0.014692559838294983\n",
      "AUC 0.9376787623870082\n"
     ]
    }
   ],
   "source": [
    "model = org_net.train_pipeline(G_dgl, epochs=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"15\": {\"11824\": 3.1207432746887207, \"11814\": 3.1207432746887207, \"0\": 3.1207432746887207, \"8304\": 3.1207432746887207, \"10497\": 3.1207432746887207}}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_net.format_output(org_net.node_output_pipelne(G_dgl, 15, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
